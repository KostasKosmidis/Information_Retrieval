{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    Υπολογίζει τις βασικές μετρικές αξιολόγησης για την ανάκτηση εγγράφων.\n",
    "    :param relevant_docs: Λίστα με τα σχετικά έγγραφα για το ερώτημα.\n",
    "    :param retrieved_docs: Λίστα με τα ανακτηθέντα έγγραφα από το σύστημα.\n",
    "    :return: Λεξικό με precision, recall και f1_score.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(relevant_docs, retrieved_docs):\n",
    "    relevant_set = set(relevant_docs)  # Σύνολο των σχετικών εγγράφων\n",
    "    retrieved_set = set(retrieved_docs)  # Σύνολο των ανακτηθέντων εγγράφων\n",
    "\n",
    "    # Υπολογισμός των True Positives (έγγραφα που είναι και σχετικά και ανακτηθέντα)\n",
    "    true_positives = len(relevant_set & retrieved_set)\n",
    "    \n",
    "    # Υπολογισμός της ακρίβειας (Precision)\n",
    "    precision = true_positives / len(retrieved_set) if retrieved_set else 0\n",
    "    \n",
    "    # Υπολογισμός της ανακλητικότητας (Recall)\n",
    "    recall = true_positives / len(relevant_set) if relevant_set else 0\n",
    "    \n",
    "    # Υπολογισμός του F1 score\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Επιστροφή των αποτελεσμάτων σε μορφή λεξικού\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "    Υπολογισμός Mean Average Precision (MAP) για πολλαπλά ερωτήματα.\n",
    "    :param relevant_docs: Λίστα λιστών με τα σχετικά έγγραφα για κάθε ερώτημα.\n",
    "    :param retrieved_docs: Λίστα λιστών με τα ανακτηθέντα έγγραφα για κάθε ερώτημα.\n",
    "    :return: Η μέση ακρίβεια (MAP).\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map(relevant_docs, retrieved_docs):\n",
    "    # Έλεγχος συμβατότητας των λιστών\n",
    "    if len(relevant_docs) != len(retrieved_docs):\n",
    "        print(f\"Ασυμβατότητα λιστών: relevant_docs={len(relevant_docs)}, retrieved_docs={len(retrieved_docs)}\")\n",
    "        return 0\n",
    "\n",
    "    ap_sum = 0  # Άθροισμα των μέσων ακρίβειας για όλα τα ερωτήματα\n",
    "    for query_id, relevant_set in enumerate(relevant_docs):  # Για κάθε ερώτημα\n",
    "        retrieved_set = retrieved_docs[query_id]  # Ανάκτηση των ανακτηθέντων εγγράφων\n",
    "        precision_values = []  # Λίστα για την αποθήκευση των τιμών ακρίβειας\n",
    "        relevant_found = 0  # Μετρητής για τα σχετικά έγγραφα που βρέθηκαν\n",
    "\n",
    "        # Υπολογισμός της ακρίβειας για κάθε ανακτηθέν έγγραφο\n",
    "        for i, doc_id in enumerate(retrieved_set):\n",
    "            if doc_id in relevant_set:  # Αν το έγγραφο είναι σχετικό\n",
    "                relevant_found += 1\n",
    "                precision_values.append(relevant_found / (i + 1))  # Υπολογισμός ακρίβειας\n",
    "\n",
    "        # Υπολογισμός της μέσης ακρίβειας (AP) για το ερώτημα\n",
    "        if precision_values:\n",
    "            ap_sum += sum(precision_values) / len(relevant_set)\n",
    "\n",
    "    # Υπολογισμός του MAP (Μέση Μέση Ακρίβεια) για όλα τα ερωτήματα\n",
    "    return ap_sum / len(relevant_docs) if relevant_docs else 0\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
